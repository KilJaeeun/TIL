# 빅데이터를 지탱하는 기술

> 시시각각 변하는 데이터를 파악하는 자동화의 세계
>
> 시스템은 데이터를 생성하고 데이터를 통해 서로 연결된다.
>
> * 규모의 제약을 넘어서는 시스템 개발을 위해
> * 데이터 처리를 시스템화하는 효율적인 방법



---



# 개요

* 제 1장 빅데이터 기초 지식은 도입부분으로 빅데이터 기술이 태어난 역사적 배경부터 시작해 기본적인 용어들을 정리한다. 여기서는 빅데이터와 대비해 이전부터 존재하는 "스몰 데이터 기술"에 대해 설명하고 있다. 간단한 파이썬 스크립트에 의한 데이터 처리와 데이터 디스커러버리를 다뤄 이에대한 개념을 이해하게 돕는다.
* 제 2장부터 제 5장까지는 기술 설명으로, 빅데이터의 시스템 구성을 몇 개의 요소로 나뉘어 순서대로 설명한다. 실제 시스템 구성은 무엇을 실현할 것인가 에 따라 변하겠지만, 이 책에서는 데이터의 시각화를 하나의 과제로 해서 가능한한 범용적으로 사용할 수 있는 요소 기술을 조합한다.
  * 제 2장 "빅데이터의 검색"에서는 데이터의 "대화적인 집계와 시각화"가 주제이다. 분류 데이터의 성질을 아직 알 수 없는 초기단계에서는 데이터의 집계를 몇 번이고 다시 실시함으로 서서히 데이터에 대한 이해를 높일 수 있다. 또한, 제 2장에서는 데이터를 초 단위로 집계하기 위한 "데이터 마트(data mart)"의 성질에 관해 설명한다.
  * 제 3장은 "빅데이터의 분산 처리"에서 하둡과 스파크 등의 분산 처리 프레임워크를 사용해 데이터를 가공 및 집계하고, 데이터 마트를 만들어내는 프로세스를 중심으로 설명한다. 
  * 제 4장 "빅데이터 축적"은 "데이터를 수집해서 보존"하는 절차를 설명한다. 이것은 단순하지만, 심호한 주제이다. 이것은 단순하지만 심오하다. 부하를 위험하기 때문이지. 몇몇 분산 스토리지의 특성을 다루면서 분산 스토리지에 데이터를 넣는 "데이터 수집"프로세스를 설명한다.
  * 제 5장 "빅데이터 파이프라인"에서는 "데이터 처리 자동화하기" 절차를 설명한다. 데이터 처리의 자동화에는 정기적으로 스케줄이 실행되는 "배치 처리"와 끊임 없이 실행되는 "스트림 처리"가 있다. 제 5장에서는 Spark를 예로 해서 배치 처리와 스트림 처리가 결합된 프레임워크를 다룸과 동시에 장애에 강한 데이터 처리를 실현하기 위해 "워크플로 관리"의 사고 방법에 관해 설명한다.
* 마지막으로 6장 "빅데이터 분석 기반의 구축"은 응용 편으로  예제를 해본다
  * 예제
    * 우선 Spark를 이용해 대화적 세션으로 데이터를 분석하고, 
    * 데이터 이해
    * 무엇을 실현할지 결정 후
    * 실제 서비스 환경에 가정해 "데이터 처리의 자동화"를 임한다. (워크플로 관리 소프트웨어 : Airfkiw)
    * 하루에 한 번 씩 데이터마트를 업데이트하는 배치 처리를 실행한다.
  * 각종 기술이 클라우드 서비스에서 어떻게 제공되는지





----

# 1장. 빅데이터의 기초 지식

> #### 키워드
>
> 데이터 웨어하우스, 하둡, NoSQL 데이터베이스,데이터 파이프라인, 데이터 레이크, 데이터 마트

## 1-1. 배경: 빅데이터 장착

> "빅데이터"가 생길때까지 역사.
>
> ~2011: 하둡이나 NoSQL 데이터베이스 등 기반 기술의 발전
>
> ~2012: 클라우드 방식의 데이터 웨어하우스나  BI 도구의 보급
>
> ~2013: 스트림 처리나 애드혹(AdHoc) 분석 환경의 확충

### 분산 시스템에 의한 데이터 처리의 고속화

* 빅데이터의 취급하기 어려운 점을 보완한 두 가지 대표 기술
* 빅데이터가 어려운 이유는 이걸 어따 써야하는지 몰라서랑 처리하는데 리소스가 많이 들어서이다.
* 웹 서버 등에 생성된 데이터는 처음에 RDB와 NoSQL 등의 텍스트 데이터로 저장된다. 이 후, 모든 데이터가 Hadoop으로 모이고, 거기서 대규모 데이터 처리가 실행된다.



#### Hadoop 

* 다수의 컴퓨터에서 대량의 데이터를 처리하기 위한 시스템이다.
* 글로벌한 서비스를 위해 다수의 컴퓨터를 이용하고, 그것을 관리하는 것이 Hadoop프레임워크이다.
* 구글에서 개발된 분산 처리 프레임워크인 MapReduce를 참고해 제작됨.
  * 그래서 초반엔 자바를 무조건이용했어야함
  * 2009년 Hive 소프트웨어 출시: SQL 같은 쿼리 언어를 하둡에서 실행할 수 있다. => 프로그래밍 없이 데이터를 집계할 수 있게 되어 사용자 확대됨.



#### NOSQL 데이터베이스

* 고속으로 빈번한 읽기, 쓰기 및 분산 처리가 강점 (SQL 과 비교)
  * 하둡(모여진 데이터를 나중에 집계가 목적) 인 Hadoop과 달리, NoSQL은 애플리케이션에서 온라인으로 접속하는 데이터베이스이다.

* 전통 RDB의 제약을제거하는 것을 목표로하는 데이터베이스의 총칭이다.
* 종류
  * 키 밸류 스토어: 다수의 키와 값을 관련지어 저장한다.
  * 도큐먼트 스토어: json 과 같은 복잡한 데이터 구조를 저장한다
  * 와이드 칼럼 스토어: 여러 키를 사용해 높은 확장성을 제공한다.





#### Hadoop 과 NoSQL 데이터베이스의 조합

> 현실적인 비용으로  대규모 데이터 처리 실현

이 둘을 조합해 NOSQL 데이터베이스에 기록하고, Hadoop으로 분산 처리하기 라는 말이 2011년 말부터 정착하게 되었고, 이제 고가의 장비보다 좀 더 싸게 먹히기 시작.







### 분산 시스템의 비즈니스 이용 개척

> 데이터 웨어하우스와의 공존
>
> (데이터웨어하우스: 데이터 저장창고인데, 분석을 할 수 있는 물리적인 서버를 의미하는 것 같다. https://ko.wikipedia.org/wiki/데이터_웨어하우스)

* EDW(enterprise data warehouse)엔터프라이즈 데이터 웨어 하우스, 또는 데이터웨어하우스 (DWH) 시대
  * 기존에 데이터웨어하우스로 기업의 의사결정을 했었다. 
  * 분산 시스템의 발전에 따라, hadoop을 이용하게 되었고, 그래서 "빅데이터"라는 키워드가 생기기 시작했다.
  * 스케일 업, 스케일 아웃에 대해 hadoop은 기존 데이터웨어하우스에 비해 유리했다.





### 직접할 수 있는 데이터 분석 폭 확대 

클라우드는 서버 안사고 오토 스케일링이 가능하니~ 더 늘었겠지 ~ 

MapReduce(하둡), BigQuery(데이터웨어하우스), HDInsight(하둡), RedShift(데이터웨어하우스) 





#### 스몰데이터와 빅데이터

스몰데이터기술, 빅데이터 기술 둘다 잘해야함.



#### 데이터 디스커버리 기초 지식

> 셀프 서비스용 BI 도구
>
> BI(비즈니스 인텔리전스)  뇌피셜, 분산데이터 등 데이터 통계, 시각화를 도와 비즈니스 결정에 도움을 준다.

빅데이터 나오는 시기에 데이터 웨어하우스에 저장된 데이터를 시각화하는 방법으로 데이터 디스커버리가 인기를 끌게 되었다.



데이터디스커버리: 대화형으로 데이터를 시각화해서 가치있는 정보를 찾으려고 하는 프로세스 




