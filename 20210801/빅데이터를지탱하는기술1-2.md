## 1-2. 빅데이터 시대의 데이터 분석 기반

> 빅데이터 기술이 기존의 데이터웨어하우스와 다른 점은 확장성이 좋다는 것이다.

### [재입문] 빅데이터의 기술

* 빅데이터의 기술이란 분산 시스템을 이용해 데이터를 순차적으로 가공해 나가는 일련의 구조이다.



#### 데이터 파이프라인

> 데이터 수집에서부터 워크플로 관리까지

일반적으로 차례대로 전달해나가는 데이터로 구성된  시스템을 데이터 파이프라인이라 한다.



#### 데이터 수집

* 벌크형과 스트리밍형의 데이터 전송
  * Bulk: 이미 어딘가에 존재하는 데이털 정리해 추출하는 방법. 데이터베이스와 파일 서버 등에서 정기적으로 데이터를 수집하는 데에 사용
  * Streaming: 차례대로 생성되는 데이터를 끊임없이 계속해서 보내는 방법으로 모바일 장비와 임베디드 장비 등에서 널리 데이터를 수집하는데 사용한다.



#### 스트림 처리와 배치 처리

스트리밍형 방법으로 받은 데이터를 실시간으로 처리하는 것이 "스트림 처리"이다. 예를 들어 30분간 취합한 데이터를 집계해 그래프를 만들려면, 시계열 데이터베이스(time seriese database)와 같은 실시간 처리를 지향하는 데이터베이스가 자주 사용된다. 스트림 처리의 결과를  시계열 데이터베이스에 저장함으로써 지금 무슨 일이 일어나는 지 알 수 있다.



* 한계: 실시간과 장기 데이터 분석 결과를 하나의 시스템에 구현하는 것은 쉬운 일이 아니다.
* 장기 데이터 분석을 위해 "배치 처리" 구조를 이용한다.



#### 분산 스토리지 

객체 스토리지, NOSQL 데이터베이스



수집된 데이터는 분산 스토리지에 저장된다. 여기서 말하는 분산 스토리지란, 여러 컴퓨터와 디스크로부터 구성된 스토리지 시스템을 의미한다. 데이터를 저장하는 방법에는 몇 가지 선택이 있다.

​	대표적인 것이 객체 스토리지로 한 덩어리로 모인 데이터에 이름을 부여해 파일로 저장한다. (AWS S3)



#### 분산 데이터 처리

* 쿼리 엔진, ETL 프로세스
* 분산 스토리지에 저장된 데이터를 처리하는데 분산 데이터 처리의 프레임워크가 필요하다. MapReduce가 사용되어진 것이 바로 이 부분
* 분산디비를 SQL 로 집계할 때는 두 가지 방법이 있다.
  * Hive라는 쿼리 엔진 사용 (현재는 대화형 쿼리 엔진)
  * 데이터웨어하우스 제품 이용 : ETL(extract-transform-load) 프로세스
  * 



#### 워크플로 관리

* 전체 파이프라인 동작을 관리하기 위해 워크플로 관리를 이용한다.
* 매일 정해진 시ㅈ간에 배치 처리를 스케줄대로 실행하고, 오류가 발생하면 관리자에게 통지
* 빅데이터의 처리에는 시스템 장애가 발생하므로 오류 발생시 처리와 다시 처리하기 위한 기능을 만드는 것을 빼놓으면 안된다.



### 데이터웨어하우스와 데이터 마트

* 데이터 파이프라인 기본형

> 데이터마트는 데이터 웨어하우스 환경에서 정의된 접근 계층으로 데이터웨어하우스에서 데이터를 꺼내 사용자에게 제공하는 역할을 한다

* 데이터웨어하우스는 대량의 데이터를 장기보존하는 것에 최적화되어있다.정리된 데이터를 한 번에 전송하는 것에 뛰어나지만, 소량의 데이터를 자주 읽고 쓰는데 적합하지 않는다.

  * 출근해서 쓰고, 야간 시간때에 정리

  ![image-20210801132737564](/Users/giljaeeun/Library/Application Support/typora-user-images/image-20210801132737564.png)

* 데이터 소스: 업무 시스템을 위한 RDB나 로그 등을 저장하는 파일 서버

  * 거기에 보존된 로우데이터(원시 데이터)를 추출하고, 필요에 따라 가공해 데이터웨어하우스에 저장하기 까지의 흐름이 ETL 프로세스이다.
  * 데이터웨어하우스 구축에는 ETL 도구라는 전용 소프트웨어가 주로 이용된다.

* 데이터 웨어하우스

  중요한 데이터가 저장되어있어 함부로 사용하는 것은 곤란. 필요한 데이터만 추출해 데이터 마트(data Mart)를 구축한다. 

* 데이터 마트

  * BI 도구와 조합시키는 형태로 데이터를 시각화하는데 사용한다.
  * 데이터웨어하우스와 데이터 마트 모두 SQL 로 집계한다. 따라서, 테이블 설계를 제대로 정한 후, 데이터를 투입한다.
  * 특히 BI 도구로 데이터를 볼 경우, 미리  시각화에 적합한 형태로 테이블을 준비해야한다.
  * 그렇기에 데이터웨어하우스를 중심으로 하는 파이프라인에서는 테이블 설계와 ETL 프로세스가 중요하다.



### 데이터 레이크

> 데이터를 그대로 축적

* 우선 데이터가 있고, 나중에 테이블을 설계하는 것이 빅데이터이다.
* 그래서 빅데이터 이전 축적 장소를 "데이터 레이크"라고 한다.
* 구체적으로 임의의 데이터를 저장할 수 있는  분산 스토리지가 데이터 레이크로 이용된다.
* 데이터레이크에서는 모든 데이터를 그대로 저장하고, 나중에 필요한 것만 꺼내 사용한다.





### 데이터 분석 기반을 단계적으로 발전시키기

시스템 구축및 운용, 자동화등을 담당하는 데이터 엔지니어와 데이터에서 가치 있는 정보를 추출하는 데이터 분석가는 요구되는 지식과 사용 도구도 다르다.

테이블 구조가 복잡할 수록 가능한 한 작은 시스템에서 시작해 나중에 단계적으로 확장해나가는 것이 좋다.



#### 애드 훅 분석 및 대시보드 도구

이 책에서 최종적으로 데이터 파이프라인의 자동화에 대해 설명할 것이다. 하지만, 아직은 시작단계이므로 자동화 등을 생각하지 않고 수작업으로 데이터를 집계할 수 있으면 충분하다.  이것을 일회성 데이터 분석이라는 의미로 애드훅(ad hoc analysis) 분석이라고 한다.

예) SQL 쿼리를 지접 작성해서 실행하거나 스프레드시트에서 그래프를 만드는 것까지 포함해 모든 수작업이 애드 훅 분석에 포함된다.

* 애드 훅 분석에서는 데이터마트를 만들 지 않을 때, 데이터 레이크와 데이터 웨어하우스에 직접 연결하는 경우가 많다. 그래서 사용자는 작업하기 쉬운 환경을 선호한다. 쿼리를 실행해, 결과를 즉시 확인할 수 있게 대화형 분석도구를 사용한다.
* 수작업으로 데이터 분석뿐만 아니라 정기적으로 그래프와 보고서를 만들고 싶을 때도 있다. 그럴ㄷ 때, 많이 도입하는 것이 '대시보드 도구'.
  * 일부 대시보드 도구는 데이터 마트가 없어도 동작하도록 설계되어있다. 설정한 스케줄에 따라 데이터 레이크와 데이터 웨어하우스에 접속해 쿼리를 실행하고, 그래프를 생성한다.



---

### 데이터를 수집하는 목적

* 검색 , 가공, 시각화의 예



#### 데이터 검색

우선 "데이터 검색"으로 대형의 데이터 중에서 조건을 맞는 것을 찾고 싶은 경우가 있다. 예를 들어, 어떤 시스템에 장애가 발생했을 때, 그 원인을 특정하면 로그를 확인하는 것과 마찬가지이다. 

데이터 검색에 너무 많은 시간이 걸리는 것은 의미가 없고  필요할 때 신속하게 검색할 수 있ㄷ록 해야한다. 따라서 시스템에는 실시간 데이터 처리나 검색 엔진을 사용해 키워드 찾는 기능이 필요하다.



#### 데이터의 가공

데이터 가공은 업무 시스템의 일부로, 데이터 처리 결과를 이용하고 싶은 경우가 있다. 웹사이트에서 추천상품을 제안하거나,  센서 데이터의 비정상적인 상태를 감지해 통보하는 경우이다. 목적이 명확하기 때문에, 필요한 데이터를 계획적으로 모아 데이터 파이프라인을설계한다. 

데이터의 가공에는 자동화가 필수적이다. 따라서, 워크 플로 관리를 도입해 꼼꼼히 테스트를 반복적으로  실행해서 시스템을 구축한다.SQL이 아닌, 프로그래밍 언어를 사용하는 경우도 있다. 이것이 데이터 분석이라기보다는 시스템 개발 영역에 해당한다.





#### 데이터 시각화

데이터를 시각화해서 정보를 얻기. 통계분석 소프트웨어나 BI 도구 등으로 그래프를 만들고 거기서 앞으로의 상황을 예측해 의사 결정에 도움을 얻는다.

시각화의 고속화를 위해 데이터 마트가 필요하고

지속변화 감시에 데이터 시각화가 필요하다.



> #### 기간계 시스템과 정보계 시스템을 분리하자.
>
> 기간계 시스템: 비즈니스에 근간이 되는 중요한 시스템. 정지되면 업무가 멈춰서 완벽한 테스트, 신중 운용
>
> 정보계 시스템:  사내 커뮤니케이션, 의사결정을 위함. 보다 덜 엄격
>
> 두 개가 혼합 안되게 하자. 사내에만 필요한 정보를 기간계 시스템에 통합하면 업데이트가 어려워 분리한다.
>
> 
>
> **데이터**란 기간계 시스템과 정보계 시스템을 연결하는 것이다. 
>
> 기간계 시스템은 그 실행 과정을 로그파일이나 데이터베이스 등에 기록한다.
>
> 정보계시스템은 데이터를 복사하는데서 시작한다.
>
> 데이터 복사 없이는 정보계 시스템이 기간계 시스템과 정보계 시스템이 연결되지 못한다. 
>
> 기간게 시스템에 부하가 걸리면, 업무에 악영향을 끼칠수도..
>
>
> 기간계 시스템의 일부로 빅데이터를 통합하는 것이 아니라면, 데이터 분석 시스템은 정보계 시스템으로 취급한다. 따라서 모든 데이터는 처음에 복사하는 것 부터 시작한다. 동일한 데이터를 여러번 꺼낼 수 있다고 단정할 수 없으므로, 한 번 복사한 데이터는 안지워라. 







### 확증적 데이터 분석과 탐색적 데이터 분석

일반적으로 데이터 분석이란 가설을 세우고, 그것을 검증하는 "확증적 데이터 분석"과 데이터를 보면서 그 의미를 읽어내려고 하는 "탐색적 데이터 분석"으로 나눌 수 있다.








