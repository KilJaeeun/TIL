# 3. 	빅데이터 분산 처리


> * **분산 시스템의 대표 프레임워크** 하둡, 스파크를 이용한 데이터 처리
> ####  3-1. 대규모 분산 처리의 프레임워크
> * 구조화 데이터와 비구조화 데이터의 차이
> * 하둡에서 구조화 데이터를 만들어 집계할 떄까지 흐름
> * **하둡**과 **스파크**의 차이
> 
> #### 3-2.
> * 쿼리 엔진: 하둡위에 구조화데이터를 집계하ㅣ기 위해 사용
>   * **Hive** : 배치형 쿼리 엔진
>   * **Presto** : 대화형 쿼리 엔진
>   * 그것들의 사용 구분
> 
> ####  3.3
> * 데이터 웨어하우스와 데이터 마트를 구성하는 각종 테이블
> * **집계 테이블** :  sql 의 집약 함수(min, max, sum)를 사용해 레코드 수를 감소시킴
> * **스냅샷 테이블** : 마우스 정보를 정기적으로 복사
> * 그것들을 결합해 비정규화 테이블을 작성하는 것 까지






## 3-1. 대규모 분산 처리의 프레임워크

> * 구조화 데이터와 비구조화 데이터의 차이
> * 하둡에서 구조화 데이터를 만들어 집계할 떄까지 흐름
> * **하둡**과 **스파크**의 차이



### 구조화 데이터와 비구조화 데이터

####  **구조화 데이터** 
	> = 스키마가 명확하게 정의된 데이터
  * sql 로 데이터 집계
  * 테이블의 칼럼명과 데이터형,  테이블 간의 관계 등을 스키마(schema)로 지정

####   **비구조화 데이터** 
	> = 스키마 없는 데이터

  * 자연어 텍스트 데이터, 이미지, 동영상 등의 미디어 데이터 
  * sql 로 집계 어려움
  * 데이터 레이크 : 비구조화 데이터를 분산 스토리지 등에 저장하고, 그것을 분산 시스템에서 처리하는 것
    * 데이터를 가공하는 과정에서 스키마 정의, 구조화된 데이터로 변환함으로써, 다른 데이터와 마찬가지로 분석할 수 있다.

####   **스키마리스 데이터**
	> = 기본 서식은 있지만,  스키마가 정의 안됨

  * Csv, json, xml 등의 데이터는 서식은 있지만, 칼럼 수나 데이터명은 명확하지 않아 스키마리스 데이터라 불린다.
  * 몇몇 nosql 데이터베이스는 스키마리스 데이터에 대응하고 있고, 데이터 레이크에서는 대량으로 축적된 스키마리스 데이터를 효율적으로 처리하도록 하는 요구도 종종있다.
  * 최근에는 인터넷을 통해 주고받는 데이터로 json 형식을 이용하는 경우가 특히 많다. 
    * 새로운 데이터를 다운로드할때마다 스키마를 정하는 것은 시간과 비용이 들어
    * json 그 대로 저장하고, 데이터 분석에 필요한 필드만 추출하는 편이 간단하다.
    * 원 데이터만 있다면, 이후에 얼마든지 추가로 꺼내면 된다.

####   **데이터 구조화의 파이프라인**
	> = 테이블 형식으로 열 지향 스토리지의 장기 보존
	이라 쓰고 어떻게 비정형 데이터가 뚝딱뚝딱  정형 데이터 마냥 저장될 수 있는지 확인해보자.

##### 2장 선행 지식 : MPP

* 열지향 스토리지에서 성능 뿜뿜 ( 하둡에서 열지향 스토리지를 만들기 위해 여러 라이브러리가 개발되고 있다. )
* 하나의 쿼리를 다수의 작은 태스크로 분해하고, 이를 가능한 병렬로 실행한다.  (`Sum(a) = sum(b)+ sum(c)`)
* 쿼리가 잘 병렬화 된다면 MPP 를 사용한 데이터 집계는 CPU 코어 수에 비례해 고속화된다.
  * 단, 디스크로부터의 로드가 병목 현상이 발생하지 않도록 데이터가 고르게 분산돼야한다.\
* MPP 는 구조상 CPU 와 디스크 모두를 균형있게 눌려야한다. 따라서, hw + sw 통합 상품으로 제공된다.
* 이처럼, 하드웨어 수준에서 데이터 집계에 최적화된 데이터베이스를 "MPP 데이터베이스"라고 한다.

* MPP 아키텍처는 하둡의 대화형 쿼리 엔진(하이브 추정)으로도 사용되고 있다.
  * 하둡에서 하이브(MPP 데이터베이스) , 프레스토(대화형 쿼리 엔진) 택은 때에 따라 다르다.
    * 하둡과의 궁합과 편리성은  프레스토 
    * 시스템 안정성과 서포트 체제 등의 측면에서는 역시 MPP 가 오랜 실적
      * But, 사용자 한명이 비싼쿼리 돌리면, 그만큼 컴퓨터 자원 99 사용중으로 모든 사용자가 영향 받을 수 있다.
      * 모니터링, 제한 시간 추가 , 사용자 리소스 제한 등을 걸지 않으면 문제가 야기될 수 있다.

|   집계 시스템 종류 | 스토리지의 종류 | 최적의 레코드 수 |
|---| --- | ---|
| RDB | 행 지향 | ~ 수천만 정도 | 
| MPP 데이터베이스 | 열지향 (하드웨어 일체형) | 수억~ |
| 대화형 쿼리 엔진 | 열지향 (분산스토리지에 보관)| 수억~ |





##### 플로우

1. 구조화 데이터로 변형 = 스키마 명확하게
2. 열지향 스토리지로 저장(데이터 압축률 향상)
   1. MPP 데이터베이스로 전송하거나, 하둡 상 열지향 스토리지 형식으로 변환
3. 구조화 데이터  = 데이터를 구조화해서 sql 로 집계가능한 테이블을 만든다.
   1. 팩트 테이블 :  시간에 따라  증가하는 데이터
   2. 디멘전 테이블 : 부속데이터 
   3. 이 단계에서는 테이블을 조인하지 않는다.
   4. 데이터 마트는 먼얘기





##### 열지향 스토리지 작성

```
분산 스토리지 상에 작성해 효율적으로 데이터를 집계
```

* MPP 데이터베이스의 경우, 제품에 따라 스토리지 형식이 고정되어있어 사용자가 그 상세를 몰라도 괜찮지만,하둡에서는 사용자가  직접 열 지향 스토리지의 형식을 선택하고, 자신이 좋아하는 쿼리 엔진에서 그것을 집계할 수 있다.

* 하둡 열지향 스토리지
  * Apache ORC 는 구조화 데이터를 위한 열 지향 스토리지로 처음에 스키마를 정한 뒤, 데이터를 저장한다.
  * Apache Parquet : 스키마리스에 가까운 데이터 구조로 되어있어 json  같은 뒤얽힌 데이터를 그대로 저장할  수 있 ㅇ다.
  * 이 책은, Apache ORC에 의한 스토리지 형식을 이용한다.
* 비구조화 데이터를 읽어 들여 열지향 스토리지로 변환하는 과정에서는 데이터의 가공 및 압축을 위해 많은 컴퓨터 리소스가 소비된다. 그래서, 하둡과 스파크 등의 분산 처리 프레임워크가 있다.

#### Hadoop : 분산 데이터 처리의 공통 플랫폼

* 역사적으로 오픈 소스의 웹 크롤러인 Nutch를 위한 분산 파일 시스템으로  2003년부터 개발되었다. 2006년에 단일 프로젝트로 독립해 Apache Hadoop 으로 배포되었다.
* 하둡은 단일 소프트웨어가 아니라 분산 시스템을 구성하는 다수의 소프트웨어로 이뤄진 집합체이다.
  * 2013년에 배포된 hadoop2 로부터 yarn 으로 불리는 새로운 리소스 관리자 상에서 복수의 분산 애플리케이션이 동작하는 구성으로 되어 대규모 분산 시스템을 구축하기 위한 공통플랫폼의 역할을 담당하고 있다.

##### 분산 시스템의 구성 요소  

> HDFS, YARN, MapReduce

* HDFS(hadoop distributed file system): 분산 파일 시스템
* YARN(yet another resource negotiator): 리소스 관리자
* MapReduce: 분산 데이터 처리

그 외의 프로덱트는 Hadoop 본체와는 독립적으로 개발되어 hadoop 을 이용한 분산 애플리케이션으로 동작한다.



* 하둡 일부, 혹은 거의 안이용하는 구성
  * hdfs+ mesos+ spark
  * 다양한 소프트웨어 중에 자신에 맞는 것을 선택하고, 그것을 조합해 시스템을 구성하는 것이 hadoop 을 중심으로 하는 데이터 처리의 특징이다.



> Spark는 MapReduce에 대한 Hadoop 개선 사항입니다. Spark와 MapReduce의 주요 차이점은 Spark는 후속 단계를 위해 데이터를 처리하고 메모리에 유지하는 반면 MapReduce는 디스크에서 데이터를 처리한다는 것입니다. 결과적으로 소규모 워크로드의 경우 [Spark의 데이터 처리 속도는 MapReduce보다 최대 100배 빠릅니다](https://databricks.com/spark/about) .
>
> https://www.ibm.com/cloud/blog/hadoop-vs-spark
>
> https://www.quora.com/How-does-YARN-compare-to-Mesos-What-are-the-key-differences





#### 분산파일 시스템과 리소스 관리자: hdfs , yarn

* 하둡에서 처리하는 데이터는 hdfs 에 저장, 네트워크에 연결된 파일 서버와 같은 존재, 다수의 컴퓨터에 파일을 복사해 중복성을 높인다.
* Yarn: cpu 나 메모리 등의 계산을 관리하는 리소스 매니저
  * 컨테이너(메모리 + cpu) 단위로 관리
  * hadoop 에서 분산 애플리케이션 실행하면, yarn 이 클러스터 전체 부하를 보고, 비어있는 호스트 부터 컨테이너를 할당한다.
  * 분산 시스템은 많은 계산 리소스를 소비하지만, 호스트의 수에 따라 사용할 수 있는 리소스의 상한이 결정된다. 
  * 리소스 관리자는 리소스 할당한다. 우선순위 결정 알골
  * yarn 컨테이너: 어떤 호스트에서 어떤 프로세스 실행시킬지 결정하는 앱 수준 기술 







#### 분산 데이터 처리 및 쿼리 엔진

> MapReduce, Hive



* MapReduce
  * 분산 시스템에서 데이터 처리를 실행하는데 사용한다.
  * 자바 프로그램 실행할 수 있어, 비구조화 데이터를 가공하는데 적합
  * 대량 데이터 배치 처리 시스템
    * 한번 실행하면, 분산 파일 시스템에서 대량의 데이터를 읽을 수 있다.
    * 작은 프로그램을 실행하려면 오버헤드가 너무 커서 몇초 안에 끝나는 쿼리(애드혹 쿼리)에 적합 하지 않다.  (하이브또한)
* Hive:
  * 쿼리 엔진 = 쿼리 언어에 의한 데이터 집계
  * 쿼리를 자동으로 MapReduce로 변환하는 소프트웨어로 개발
  * 초기, mapreduce에 의존 (장단점)
  * Hive = tez+ mapreduce (reduce time)
* tez : mapreduce - wait time



#### Presto & Impala

* 대화형 쿼리 전문
* 순간 최대 속드를 높이기 위한 모든  오버헤드 제거해, 사용할 수 있는 모든리소스 활용해 리소스 실행 
* mpp 와  유사한 응답속도 (멀티 코어)







#### 등등

* sql on hadoop







###  Spark

> 인메모리형 고속 데이터 처리

* 가능한, 많은 데이터를 메모리에 두어 디스크에 아무것도 두지 않는다. -> 빠른 속도 , 휘발성

* mapreduce 대체, not hadoop 에서도 사용 (예, S3, 카산드라)

* spark는 자바 런타임이 필요하지만, spark 데이터 처리는 스크립트 언어를 사용할 수 ㅣㅇㅆ다.

* sql , 스트림 처리를 위한, spark streaming 이라는 기능으로 실시간 스트림 처리 가능

  대규모 처리 + sql 대화형 쿼리  + 실식산 스트림 처리 다 가능



-----



## 3-2. 쿼리 엔진

> * 쿼리 엔진: 하둡위에 구조화데이터를 집계하ㅣ기 위해 사용
>   * **Hive** : 배치형 쿼리 엔진
>   * **Presto** : 대화형 쿼리 엔진
>   * 그것들의 사용 구분



### 데이터 마트 구축의 파이프라인

예) hive(데이터 구조화) + presto(데이터 집약) 결합 데이터 파이프라인

* 하이브에서 만든 각 테이블 정보는  Hive 메타 스토어라고 불리는 특별한 데이터베이스에 저장된다. 이것은 hive 뿐 아니라, sql on hadoop의 쿼리 엔진에서도 공통의 테이블 정보로  참고 된다.



### Hive에 의한 구조화 데이터 작성

```
# hive 가동
$ hive

# 외부 테이블 'access_log_csv' 정의 : 특정 파일을 마치 테이블 처럼 읽기
hive > CREATE EXTERNAL TABLE access_log_csv(
time string, request string, status int, bytes int
)
# csv 형식임을 지정
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
# 경로를 지정(디렉토리 내의 모든 파일 읽어옴)
STORED AS TEXTILE LOCATION '/var/log/access_log'
# csv 헤더 스킵
TELPROPERTIES('skip.header.line.count='='1);

# 데이터를 그자리에서 바로 집계 가능(8분)
select status from access_log_csv;
```





* hive 를 비롯한 대부분의 sql on hadoop 의 쿼리 엔진은 mpp 데이터베이스처럼 데이터를 내부에 가져오지 않아도 텍스트 파일을 그대로 ㅣㅈㅂ계할 수 ㅣㅇㅆ다.
* 데이터를 그자리에서 바로 집계 가능

* 8초 : 느리다 -> 열지향 스토리지로 변환해야함.



#### 열지향 스토리지로의 변환

* 데이터 집계의 고속화(배치형 쿼리 엔진용)

* 열지향 스토리지 형식인 ORC 로 변환한다.

* hive 의 경우, 테이블마다 스토리지 형식을 지정할 수 있다. 다음과 같이 새로운 테이블을 만들고, 외부 테입블마다 읽은 데이터를 저장한다.

* ```
  # ORC 형식의 테이블 'access_log_orc'로 변환
  CREATE TABLE access_los_orc STORED AS ORC AS
  SELECT cast(time as timestamp) time,
  request, 
  status, 
  cast(bytes AS bigint) bytes
  FROM access_log_csv;
  
  
  # 데이터를 그자리에서 바로 집계 가능 ( 1.5초 )
  select status from access_log_orc;
  ```











#### hive로 비정규화 테이블을 작성하기

* 데이터 마트 구축
* 테이블 결합 + 집약으로 비정규화 테이블을 만든다
* 쿼리 엔진을 대화형(presto)? 배치형(hive)에 따라 생각이 달라진다.
  * 수억개 데이터 = 쿼리 엔진 자체의 성능은 최종적인 실행시간에 그렇게 많은 영향을 끼치지 않는다. = 배치형이 리소스 이용효율 높임(이해 안가)
  * 되도록 효율 쿼리 작성할 것



#### 서브 쿼리 안에 레코드 수 줄이기

* 데이터 양 의식하면서 쿼리 작성하기
* 초기 단계에 팩트 테이블을 작게 해야 성능이 잘나온다.





##### 데이터 편향 피하기

* 분산 시스템의 성능 발휘를 위해



* 최초의 중복을 없애라.

* distinct: 중복이 없는 값을 세려면, 데이터를 한 곳에 모아야해서 분산 처리하기 어려워지기 떄문이다.
* distrinv count는 분산되지 않아도, group by 에 의한 그룹화는 분산처리 된다.





#### 대화형 쿼리 엔진 Presto의 구조

* 페이스북 출시
* 플러그인 가능한 스토리지 설계 
  * 하나의 쿼리 안에 여러 데이터 소스에 연결 가능하다.
    * 하나의 코디네이터와 여러 워커
* ORC 에 최적화
* 고속 네트워크 이요시 빠름

* CPU 처리의 최적화



자바 -(자바인터프리터)-> 바이트코드 (.class) -jvm 런타임영역->  기계어로 바꾼다.



* ​	

* 스레드. vs 프로세르

  * 라이프사이클 빠르고
  * 용량 작고
  * ...
  * 
  * s

  * 읽기와 코드 실행 병렬 처리
  * presto 는 sql 의 실행에 특화된 시스템으로, 쿼리를 분석해 최적의 실행 계획을 생성하고, 그것을 자바의 바이트코드로 변환한다. 바이트코드는 presto 의 워커 노드에 배포되고, 그것은 런타임 시스템에 의해 기계 코드로 컴파일 된다.
  * 코드의 실행은 멀티 스레드화되어 단일 머신에서 수백 태스크나 병렬로 실행된다.
  * presot의 cpu 이용 효율이 높으므로 메모리와 cpu 릿스만 충분하다면, 데이터의 읽기 속도가 쿼리의 실행 시간을 결정하게 된다.

* hive와 달리 presto 는 쿼리의 실행과정에서 디스크에 쓰기를 하지 않는다. 모든데이터의 처리를 메모리에서 실시하고, 메모리 부족하면 기다리던지 오류로 실패한다. 메모리 할당 늘리거나, 쿼리를 다시 작성해야한다.
  * groupby 는 메모리 소비량이 고정





#### 분산 결합과 브로드캐스트 결합

* 분산결합은  디멘젼 테이블 각 속성을 서버에 박아 분리
* 브로드 캐스트 결합 = 디멘션 테이블을 각 서버에 박아 미리 분리 후 합치기

----



## 3.3

> * 데이터 웨어하우스와 데이터 마트를 구성하는 각종 테이블
> * **집계 테이블** :  sql 의 집약 함수(min, max, sum)를 사용해 레코드 수를 감소시킴
> * **스냅샷 테이블** : 마우스 정보를 정기적으로 복사
> * 그것들을 결합해 비정규화 테이블을 작성하는 것 까지

