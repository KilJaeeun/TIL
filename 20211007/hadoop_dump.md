* 데이터 수집 기술

  * Flume 

    * 플룸은 많은 양의 로그 데이터를 효율적으로 수집, 취합, 이동하기 위한 분산 소프트웨어

  * Kafka

    * 오픈 소스 메시지 브로커 프로젝트

  * Sqoop

    * 관계형 데이터베이스와 아파치 하둡 간의 대용량 데이터들을 효율적으로 변환하여 주는 명령줄 인터페이스 애플리케이션

  * Nifi

    * 소프트웨어 시스템 간 데이터 흐름을 자동화하도록 설계된 소프트웨어 프로젝트

  * Flink

    * 오픈 소스 스트림 처리 프레임워크

  * Splunk

    * 기계가 생성한 빅데이터를 , 웹 스타일 인터페이스를 통해 검색, 모니터링 분석하는 소프트웨어

  * Logstash

    * 실시간 파이프라인 기능을 가진 오픈 소스 데이터 수집 엔진

  * Fluentd

    * 크로스 플랫폼 오픈 소스 데이터 수집 소프트웨어 프로젝트

      





## 2-정제

정제 단계는 데이터를 분석 가능형태로 정리하는 것입니다.  여러 경로에서 수집된 데이터가 형식이 다르기 때문에 분석 단계에 사용할 도구에 맞는 형태로 변환합니다 데이터를 변환할 때 오류 데이터, 불필요한 데이터를 제거합니다. 정제한 데이터는 압축하여 데이터 사이즈를 줄여줍니다.



### 정제 단계

* identification

  * 알려진 다양한 데이터 포맷이나 비정형 데이터에 할당된 기본 포맷을 식별

* Filtration

  * 수집된 정보에서 정확하지 않은 데이터는 제외

* Validation

  * 데이터 유효성을 검증

* Noise Reduction

  * 오류 데이터를 제거
  * 분석불가능한 데이터는 제외

* Transformation

  * 데이터를 분석가능한 형태로 변환

* Compression

  * 저장장치 효율성을 위해 변환한 데이터를 압축

* Integration

  * 처리 완료한 데이터 적재

  

  

---

## 3 - 적재

적재 단계는 대량의 데이터를 안전하게 보관하고 분석할 수 있는 환경으로 옮기는 것이다.
분석에 사용할 도구에 따라 NoSQL, RDB, 클라우드 스토리지, hdfs 등 다양한 환경으로 데이터를 적재한다. RDB 에 추출한 데이터나, csv 형태로 제공되는 데이터는 별도의 정제 단계없이 바로 적재할 수 있다.





## 4 - 분석

분석단계는 적재된 데이터를 이용해 의사 결정을 위한 데이터를 제공하기 위한 리포트를 생성하는 단계이다.

대용량의 데이터를 빠르게 분석하기 위한 처리 엔진이 필요하고, 효율적으로 분석하기 위해 파티셔닝, 인덱싱 등의 기술이 필요하다. 실시간 분석, 배치 분석 등을 이용해 리포트를 생성한다.



## 5 - 시각화

최종적으로 시각화단계이다. 너무 많은 데이터는 정보 과잉으로 사용자가 확인하기에 부담이 될 수 있기 때문에 사용자가 빠르게 인식할 수 있는 형태의 시각화가 필요하다.





# 3 - 빅데이터 에코시스템

빅데이터는 수집, 정제, 적재, 분석, 시각화의 여러 단계를 거친다.이 단계를 거치는 동안 여러가지 기술로 이용해 처리되고, 이 기술들을 통틀어 빅데이터 에코 시스템이라 한다.



## 수집 기술

수집 기술은 빅데이터 분석을 위한 원천 데이터를 수집하는 기술입니다. 원천 데이터는 실시간 데이터 수집 기술, 배치 데이터 수집 기술이 있습니다. 원천데이터의 종류 로그 데이터 , DB 데이터, api 호출 데이터 등 여러가지 종류가 있습니다.



## 플룸(Flume)

플룸은 클라우데라에서 개발한 서버 로그 수집 도구입니다. 각 서버에 에이전트가 설치되고, 에이전트로부터 데이터를 전달받는 콜렉터로 구성됩니다.

> * apache flume



## 카프카(Kafka)

카프카는 링크드인에서 개발한 분산 메시징 시스템이다. 대용량 실시간 로그 처리에 특화되어있습니다. 발행(publish) - 구독(subscribe)모델로 구성됩니다.



> * kafka



### NiFi

미국 국가 안보국(NSA) 에서 개발한 시스템 간 데이터 전달을 효율적으로 처리, 관리, 모니터링하기 위한 최적의 시스템이다.



### Sqoop

RDBMS 와 hdfs 간의 대용량 데이터 전송을 위한 솔루션입니다. hdfs, rdbms, dw, nosql  등 다양한 저장소에 대용량 데이터를 신속하게 전송할 수 있는 방법을 제공합니다. 상용 rdbms 도 지원하고, mysql , postrgresql 오픈소스 rdbms 도 지원합니다.



### scribe

스크라이브는 페이스북에 제작된 로그 수집 시스템입니다. 메시지 큐에 쌓인 로그를 db 나 메시지 큐로 전달합니다. c++ 로 제작되어 속도가 빠르고, 페이스북의 대용량 데이터 처리에 사용될 정도로 안정성을 가지고 있습니다.









----

## 용어

### Event

* flume 에서 전달하는 데이터 단위
* 헤더와 바디로 구성
  * 헤더 : 설정 값, 딕셔너리 형태
  * 바디: 전달할 데이터
  * 

### Agent

* 에이전트는 소스, 채널, 싱크로 구성된 데이터 수집을 위한 jvm 프로세스

* 소스로 입력된 메시지를 채널에 저장하고, 저장된 메시지 묶음을 싱크로 전달

* 소스(Source)

  * 웹 서버 같은 외부 소스에 의해 전달되는 이벤트를 수집

  * 외부 소스는 Flume 이 인식하는 형태로 이벤트를 전달
  * Avro, Thrift, File Http 소스 등이 있다.

* 채널(Channel)

  * 소스가 이벤트를 수신하면, 채널에 임시 저장
  * 채널은 싱크가 이벤트를 다른 목적지로 전달할 때까지 파일이나 메모리 등에 이벤트를 보관
  * 메모리, File, Kafka , DB 채널 등이 있음

* 싱크(Sink)

  * 채널에 저장된 이벤트를 외부저장소, 다름 플룸 에이전트로 전달
  * 소스와 싱크를 비동기적으로 진행
  * hdfs, hive, thrift, avro   싱크가 있음







## 채널 셀렉터(Channel Selector)

* 하나의 소스에 다수의 채널이 연결되어있을 때, 다수의 채널이 연결되어있을 때,  이벤트를 전달하는 기준으로 복제, 멀티 플렉싱이 있다.
* 복제: 모든 채널에 동일한 이벤트를 전달, 기본 설정
* 멀티 플렉싱:  헤더 정보를 이용해 분기





### 싱크 프로세서(Sink Processors)

* 채널에 연결된 싱크를 그룹으로 묶어서 사용
* 기본 설정은 하나의 싱크를 사용하고, failover 모든 시 우선 순윈가 높은 모드부터 사용하다가 오류가 ㄴ발생하면 다음 순위의 싱크를 사용한다.





### 인터셉터(Interceptor)

* 소스로 들어온 이벤트의 헤더를 수정하거나 내용을 추가할 때, 사용
  * 시간 추가나, 수집 서버 정보를 추가할 때 사용





## 연결 모드

* Multi-agent  flow
  * 에이전트릐 싱크와 소스를 연결하여 다수의 에이전트를 링크드 리스트처럼 연결

* consolidation
  * 하나의 에이전트가 여러 에이전트에서 수집한 데이터를 받아서 처리

* Multiplexing the flow
  * 하나의 에이전트에서 여러 개의 채널로 이벤트를 전달





---

# 2 - Kafka

Kafka는 LinkedIn에서 개발한 분산 스트리밍 플랫폼입니다. 메시징, 메트릭 수집, 로그 수집, 스트림 처리 등 다양한 용도로 사용할 수 있습니다. 2020년 5월 기준 2.5.0 버전이 최신 버전입니다.

## 특징

- 빠르다: Fast
  - 수 천개의 데이터 소스로 부터 초당 수백 메가바이트의 데이터를 입력 받아도 안정적으로 처리 가능
- 확장가능: Scalable
  - 메시지를 파티션으로 분리햐여 분산 저장, 처리할 수 있어 클러스터로 구성하여 확장 가능
- 안정적이다: Durable
  - 클러스터에 파티션 복제하여 장애 내구성을 가짐





## 발행/구독(Pub/Sub) 모델

* Kafka는 발행-구독(Pub/Sub)모델을 기반으로 동작합니다. 발행-구독 모델은 발행자(Producer)가 메시지를 특정 수신자에게 직접 보내는 방식이 아니라 주제(topic)에 맞게 브로커에게 전달하면 구독자(Consumer)가 브로커에 요청해서 가져가는 방식입니다.
  - 발행자는 메시지를 topic으로 카테고리화
  - 구독자는 topic에 맞는 메시지를 브로커에게 요청
  - 발행자와 구독자는 서로 알지 못함



---





# 하둡 생활코딩

https://www.youtube.com/watch?v=HCR1ILMROfI



* 빅데이터의 저장과 분석을 위한 분산 컴퓨팅 솔루션



----

# 4 - YARN

YARN(Yet Another Resource Negotiator) 은 하둡2에서 도입한 클러스터 리소스 관리 및 애플리케이션 라이프 사이클 관리를 위한 아키텍처이다.



## 등장배경

하둡1에서는 잡트래커가 애플리케이션의 라이프사이 관리와 클러스터 리소스 관리를 모두 담당하여 병목현상이 발생했다.

잡트래커 한 대가 클러스터의 모든 노드를 관리해야하고, 모든 애플리케이션의 관리하였기 때문에 잡트래커에 많은 메모리를 할당해야했고, 최대 4000대의 노드까지 관리할 수 있습니다.

잡트래커는 슬롯 단위로 리소스를 관리해 시스템의 전체 자원을 효율적으로 사용할 수 없었습니다. 슬롯 단위 리소스 관리는 클러스터의 메모리, cpu 자원을 분할하여 슬롯 단위로 구분합니다. 100GB 의 메모리를 가지는 클러스터를 1G 로 구분하여 100개의 슬롯을 만들고 60개의 맵슬롯, 40개의 리듀서 슬롯으로 구분합니다. 슬롯을 각각의 역할에 맞게 동작할 수 있다. 따라서 맵슬롯이 동작하는 동안 리듀서 슬롯으로 구분합니다. 슬롯은 각각의 역할에 맞게 동작할 수 있다. 따라서 맵 슬롯이 동작하는 동안, 리듀서 슬롯은 대기하게 됩니다. 맵슬롯에 더 많은 일을 하게 되더라도 리듀서 슬롯은 대기하게 됩니다.

잡 트래커의 애플리케이션은 맵리듀스 작업만 처리할 수있어서 유연성이 부족하였습니다. 맵 리듀스 api를 구현한 작업만 처리할 수 있었기 때문에 sql 기반 작업의 처리나, 인메모리 기반의 작업의 처리에 어려움이 있었습니다.

이런 단점을 극복하기 위하여 YARN 아키텍처가 도입되었습니다.



## YARN 구성

YARN은 잡트래커의 기능을 분리하여  자원 관리는 리소스 매니저와 노드 매니저, 애플리케이션 라이프 사이클 관리 기능은 애플리케이션 마스터와 컨테이너가 담당하도록 하였습니다.



### 자원 관리

클러스터 자원 관리는 리소스 매니저(Resource Manager)와 노드 매니저(Node Manager)를 이용해 처리합니다.

노드매니저는 클러스터의 각 노드마다 실행됩니다. 현재 노드의 자원 상태를 관리하고 리소스 매니저에 현재 자원 상태를 보고합니다.

리소스 매니저는 노드 매니저롭터 





---

# 6장 빅데이터 분석 기반의 구축

## 6-1. 스키마리스 데이터의 애드혹 분석

* 애드혹 데이터 분석에는  데이터 처리를 조금씩 대화식으로 실행할 수 있는 소프트웨어를 선호한다.
* 이 절에서는 그 예로 json 에 의한 스키마리스 데이터를 집계하는 절차에 관해 설명한다.

> #### 노트
>
> 이 절에서는 다음과 같은 소프트웨어에 관해 설명한다.
>
> * 데이터 소스 -> twitter tm



### spark 에 의한 분산환경 - 데이터 양이 늘어도 대응 가능하게 하기


